<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Stacy Shang - Computational Linguistics</title>
        <link href="css/layout.css" rel="stylesheet">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Domine:wght@400..700&display=swap" rel="stylesheet">
        <script src=https://kit.fontawesome.com/38a2cc942e.js crossorigin="anonymous"></script>
    <body>
        <header>
            <h2 class="header">Stacy Shang</h2>
            <nav>
                <ul>
                    <li><a href="../index.html">Home</a></li>
                    <li><a href="about.html">About</a></li>
                    <li><a href="portfolio.html">Portfolio</a></li>
                    <li><a href="resume.html">Resume</a></li>
                </ul>
            </nav>
        </header>
        <main>
            <h1 class="portfolio">Computational Linguistics</h1>
            <div class="portfolio_section_wrapper">
                <article>
                    <h2>German morphological inflections model</h2>
                    <p>I worked with students in my computational linguistics course to improve a model that generated predictions for German morphological inflections. The model was provided with a training set and given a development set containing lemmas (root forms) of German words to generate predictions for inflected forms. My group focused on improving the model's accuracy with handling separable prefixes in German.</p>
                    <p><a href="https://github.com/pseudonijus/Deutsch_409_Generating-morphological-inflections/blob/main/JupyterNotebook/409-GermanFinal.ipynb">View the GitHub repository</a></p>
                </article>
                <article>
                    <h2>N-gram model</h2>
                    <p>I created a model that generated random nonce words based on probabilities of bigrams and trigrams within a given dictionary of English words. The model also calculated the probabilities of a given list of nonce words, as well as a rating of how English-like the list is based on its perplexity.</p>
                    <p><a href="https://github.com/stacy-shang/advanced-computational-linguistics/tree/main/HW2-files">View the GitHub repository</a></p>
                </article>
                <article>
                    <h2>CKY parsing algorithm</h2>
                    <p>I implemented the Cocke–Younger–Kasami (CKY) algorithm. The program parses a corpus of sentences and returns the possible underlying syntactical structures of each sentence, as well as its probability based on a context-free grammar.</p>
                    <p><a href="https://github.com/stacy-shang/advanced-computational-linguistics/tree/main/HW5-files">View the GitHub repository</a></p>
                </article>
            </div>
        </main>
        <footer>
        <div class="links">
            <ul>
                <li><a href="mailto:stacyshang@umass.edu" aria-label="Email"><i class="fa-regular fa-envelope" aria-hidden="true"></i></a></li>
                <li><a href="https://www.linkedin.com/in/stacy-shang-135012297/" aria-label="LinkedIn"><i class="fa-brands fa-linkedin" aria-hidden="true"></i></a></li>
                <li><a href="https://github.com/stacy-shang" aria-label="GitHub" ><i class="fa-brands fa-github" aria-hidden="true"></i></a></li>
            </ul>
        </div>
        </footer>
    </body>
</html>

